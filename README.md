# NeuroBird
The NeuroBird: Using Steady-State Visually Evoked Potentials to Guide a Drone through an Obstacle Course


This project explores how distinct steady-state visually evoked potentials (SSVEPs) in the occipital lobe, induced by different frequencies of strobe lights, can be harnessed for drone flight control. In our implementation, a drone will move forward through a simple obstacle course, with a live video feed from its front camera streamed to the user in real time. The user will face two screens of different frequencies, where the left screen's strobe pattern corresponds to a leftward movement in the drone and the right screen's strobe pattern corresponds to a rightward movement. 

Our project is a proof of concept that SSVEP features in EEG data are sufficiently distinguishable by machine learning algorithms to be used in place of traditional tactile input methods.

This project was developed by Alex Czerminski, Sofia Fischel, Angelina Gyves, Anthony Noshy, Priyanshi Singh, and Shreya Vallala.
